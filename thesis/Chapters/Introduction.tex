\chapter{Introduction}
With the ever increasing need for storage and computational power,
governments, research institutes and industry are rushing to adopt
Cloud Computing, moving away from a model where computational projects
are executed on local computers.

The communities of researchers that need access to the computational
power required to carry out non-trivial simulations and analysis of
data are often distributed geographically, as are the computing
resources they rely on.

\highlight{something}

\section{Background}

\highlight{computations with potential for strong scaling, sampling
  molecular simulations}

\highlight{does not use available power}

%Cloud Computing and Grid Computing 360-Degree Compared:

%''Nevertheless,yes: the problems are mostly the same in Clouds and
%Grids. There is a common need to be able to manage large facilities;
%to define methods by which consumers discover, request, and use
%resources provided by the central facilities; and to implement the
%often highly parallel computations that execute on those resources.''

%''Provenance is still an unexplored area in Cloud environments, in
%which we need to deal with even more challenging issues such as
%tracking data production across different service providers (with
%different platform visibility and access policies) and across
%different software and hardware abstraction layers within on
%provider.''


%Copernicus paper

%Many interesting real-world applications (all that are not
%embarrassingly parallel) require some interprocess communication for
%scaling and are therefore limited both by the availability of this
%bandwith as well as the total amount of resources for high absolute
%performance.

%Molecular dynamics simulations pose significant computaional
%challanges. The systems are big enough to be parallelized, with
%100-500 particles assigned to each core in high-performance molecular
%dynamics (MD) packages such as Gromacs [10, 17] when run on a system
%with sufficiently low interconnect latency.

\subsection{Copernicus}
Copernicus is a software system that is made to distribute and
parallelize large molecular dynamics simulations. The system
integrates elements from distributed computing, and applies them to
more traditional high-performance compute clusters. By taking
advantage of the fast interconnects that may be available on these
compute environments, individual simulations are parallelized as far
as possible. This approach enables Copernicus to use
orders-of-magnitude more cores than a traditional simulation run on a
sumpercomputer, and it allows for larger-scale simulations than would
be possible with purely distributed systems, while it reduces
time-to-solution significantly.

The idea behind Copernicus is to exploit the inherent parallelism of
ensemble simulation and to make use of advanced sampling algorithms,
while keeping the performance advantages of massively parallel
simulations. Such computations are called projects in the system.

\begin{quote}
  A project is executed as a single job, but breaks it up into coupled
  individual parallel simulations over all available computational
  resoureces, with the single simulation as the individual work
  unit. While the software has been optimized for using multiple
  high-performance compute clusters, it works equally well with cloud
  computing instances or even individual
  workstations.\citep{pronk:2011}
\end{quote}

To handle projects with many simulations as a single entity Copernicus
needs to able to
\renewcommand{\labelitemi}{-}
\begin{itemize}
\item match and distribute the individual simulations to the available
  computational resources,
\item run simulations on a variety of remote platforms simultaneously:
  HPC clusters, workstations, cload copmuting instances, et cetera,
\item parallelize tasks to the maximum extent possible on each
  resource, and use adaptive coupling beyond this,
\item allow flexibility in the types of projects tat can be run,
\item perform real-time analysis of the running project.
\item enable monitoring of running projects.\citep{pronk:2011}
\end{itemize}

Copernicus network structure conatians three components: clients,
servers and wrokers. The clients are user interfaces to interact with
the system. Users will send and start their computational project to a
server using the client. The server handels the project and controls
the work distribution. Jobs will be sent to available workers,
depending on which worker is best suited for the job. A worker will
calculate the jobs assigned to it and send the result back to the
server. It will also announce to servers when it is
available. Multiple worker processes can be run on the same system,
e.g. supercomputers would run a great number of wokers to use all the
available cores.

Copernicus projects are described by building computational data-flow
networks. A network is a set of connections between black boxes, where
a black box can either be a function or another network. Both
functions and networks have external inputs and outputs which are used
to connect the networks between scopes. A function has a subnetwork
and a controller which both can't be accessed outside the
function. The subnetwork is a normal network where the controller can
add connections and black boxes. Controllers are basically event
handlers that trigger in certain situations, e.q. they are called when
a project starts, a subproject finishes, a command finishes,
etc\citep{pronk:2011}.

%There are primitive types like files, strings, ints, etc. There are
%also compound types lists, dictionaries and function types

The problem with Copernicus was the lack of a good way to describe
projects. There were no intuitive way of giving input to the system,
and that is why this project was formed.


\section{Problem statement}
The objective is to find and implement a solution for the need of a
new way of giving Copernicus information of the users projects. The
developers specifically stated that the wanted a domain-specific
language(DSL) for this solution, and that they later on want to add a
graphical solution using this DSL.

The DSL should allow users of Copernicus to define their computational
projects. The projects should be able to be defined as piping
computations in a data-flow network, which means that the DSL needs to
be able to describe data-flow networks in plain text.

The intended users are assumed to possess some knowledge of
programming, but are not necessarily adept programmers. The design of
the DSL should therefore be simple and intuitive. The DSL needs to be
easy to understand so it becomes an asset instead of an hindrance.

The DSL should be fully functional in Copernicus. The users needs to
be able to use all the features and properties available in
Copernicus.

Copernicus has plug-in libraries which needs to be usable in the
language. This implies a certain amount of flexibility since there are
not a static amount of plug-ins, as new ones can be added. The DSL
should be able to cope with any new plug-ins.

The implementation should have an output of a form so that it can
easilly be integrated in the Copernicus system. The implementation
also needs to be easy to install on any system, supercomputer or
other.

\subsection{Delimitations}
The most important part of the project is to have a working
implementation. There are features which can be added to the DSL for
describing even more advanced projects with better syntax, e.g. simple
arithmetics.

The implementation generates XML code since Copernicus already has
support for reading XML files describing computational projects. This
will most likely be replaced by building the projects directly from
the abstract syntax trees, rendering the XML generation
redundant. This step would require much more understanding of how
Copernicus work, which is not within the time limit of this project.

This project has not considered a graphical solution at all. Graphical
implementations of related work has only been used get inspiration for
the DSL. A graphical interface would be good addition, but it is
another project. Such a solution can use many parts of the developed
DSL implementation.

The language we chose to write the implementation in is Python. This
choice was based on formost an easy implementation and maintenance,
since Copernicus is written in Python. It would have been possible to
use effective tools and another language, but instead tools
specifically for python were used.


%\subsection{Purpose}


\section{Literature}


\section{Related work}


\section{Remaining chapters}
The chapters in the next part will cover the different parts of the
project in a fashion fairly close to the different stages the project
went through.

The research conducted to gather domain knowledge is presented in
\autoref{chap:research}. In \autoref{chap:language}, the language, its
features and various design choices will be covered. The actual
implementation details are described in \autoref{chap:implementation}.
