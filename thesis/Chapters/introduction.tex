\chapter{Introduction}
With the ever increasing need for storage and computational power,
governments, research institutes and industry are rushing to adopt
Cloud Computing, moving away from a model where computational projects
are executed on local computers.

The communities of researchers that need access to the computational
power required to carry out non-trivial simulations and analysis of
data are often distributed geographically, as are the computing
resources they rely on.

\highlight{something}

\section{Background}

\highlight{computations with potential for strong scaling, sampling
  molecular simulations}

\highlight{does not use available power}

%Cloud Computing and Grid Computing 360-Degree Compared:

%''Nevertheless,yes: the problems are mostly the same in Clouds and
%Grids. There is a common need to be able to manage large facilities;
%to define methods by which consumers discover, request, and use
%resources provided by the central facilities; and to implement the
%often highly parallel computations that execute on those resources.''

%''Provenance is still an unexplored area in Cloud environments, in
%which we need to deal with even more challenging issues such as
%tracking data production across different service providers (with
%different platform visibility and access policies) and across
%different software and hardware abstraction layers within on
%provider.''


%Copernicus paper

%Many interesting real-world applications (all that are not
%embarrassingly parallel) require some interprocess communication for
%scaling and are therefore limited both by the availability of this
%bandwith as well as the total amount of resources for high absolute
%performance.

%Molecular dynamics simulations pose significant computaional
%challanges. The systems are big enough to be parallelized, with
%100-500 particles assigned to each core in high-performance molecular
%dynamics (MD) packages such as Gromacs [10, 17] when run on a system
%with sufficiently low interconnect latency.

\subsection{Copernicus}
Copernicus is a software system that is made to distribute and
parallelize large molecular dynamics simulations. The system
integrates elements from distributed computing, and applies them to
more traditional high-performance compute clusters. By taking
advantage of the fast interconnects that may be available on these
compute environments, individual simulations are parallelized as far
as possible. This approach enables Copernicus to use
orders-of-magnitude more cores than a traditional simulation run on a
sumpercomputer, and it allows for larger-scale simulations than would
be possible with purely distributed systems, while it reduces
time-to-solution significantly.

The idea behind Copernicus is to exploit the inherent parallelism of
ensemble simulation and to make use of advanced sampling algorithms,
while keeping the performance advantages of massively parallel
simulations. To handle projects with many simulations as a single
entity Copernicus must be able to\citep{pronk:2011}:

\begin{quatation}
  \begin{itemize}
  \item Match and distribute the individual simulations to the
    available computational resources
  \item Run simulations on a variety of remote platforms
    simultaneously: HPC clusters, workstations, cload copmuting
    instances, et cetera.
  \item Parallelize tasks to the maximum extent possible on each
    resource, and use adaptive coupling beyond this.
  \item Allow flexibility in the types of projects tat can be run.
  \item Perform real-time analysis of the running project.
  \item Eneble monitoring of running projects.
  \end{itemize}
\end{quatation}

%Copernicus paper

%A project is executed as a signle job, but breaks it up into coupled
%individual parallel simulations over all available computational
%resoureces, with the single simulation as the individual work
%unit. While the software has been optimized for using multiple
%high-performance compute clusters, it works equally well with cload
%computing instances or even individual workstations.

%Controllers are in essence event handlers that react to a set of
%conditions: ther are colled when a project starts, a subproject
%finishes, a command finishes, etc. In response to these events,
%controllers can initiate and perform post-processing of data
%generated by commands.

\highlight{server worker client}

\highlight{last: no good way of describing computational projects}

\section{Problem statement}
The objective is to find and implement a solution for the need of a
new way of giving Copernicus information of the users projects. The
developers specifically stated that the wanted a domain-specific
language(DSL) for this solution, and that they later on want to add a
graphical solution using this DSL.

The DSL should allow users of Copernicus to define their computational
projects. The projects should be able to be defined as piping
computations in a data-flow network, which means that the DSL needs to
be able to describe data-flow networks in plain text.

The intended users are assumed to possess some knowledge of
programming, but are not necessarily adept programmers. The design of
the DSL should therefore be simple and intuitive. The DSL needs to be
easy to understand so it becomes an asset instead of an hindrance.

The DSL should be fully functional in Copernicus. The users needs to
be able to use all the features and properties available in
Copernicus.

Copernicus has plug-in libraries which needs to be usable in the
language. This implies a certain amount of flexibility since there are
not a static amount of plug-ins, as new ones can be added. The DSL
should be able to cope with any new plug-ins.

The implementation should have an output of a form so that it can
easilly be integrated in the Copernicus system. The implementation
also needs to be easy to install on any system, supercomputer or
other.

\subsection{Delimitations}
The most important part of the project is to have a working
implementation. There are features which can be added to the DSL for
describing even more advanced projects with better syntax, e.g. simple
arithmetics.

The implementation generates XML code since Copernicus already has
support for reading XML files describing computational projects. This
will most likely be replaced by building the projects directly from
the abstract syntax trees, rendering the XML generation
redundant. This step would require much more understanding of how
Copernicus work, which is not within the time limit of this project.

This project has not considered a graphical solution at all. Graphical
implementations of related work has only been used get inspiration for
the DSL. A graphical interface would be good addition, but it is
another project. Such a solution can use many parts of the developed
DSL implementation.

The language we chose to write the implementation in is Python. This
choice was based on formost an easy implementation and maintenance,
since Copernicus is written in Python. It would have been possible to
use effective tools and another language, but instead tools
specifically for python where used.


%\subsection{Purpose}


\section{Literature}


\section{Related work}

\section{Remaining chapters}

